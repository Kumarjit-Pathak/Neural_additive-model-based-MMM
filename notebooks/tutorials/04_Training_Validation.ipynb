{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9022d22f",
   "metadata": {},
   "source": [
    "# Notebook 4: Training and Validation\n",
    "## Properly Training NAM for Time Series Data\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Implement walk-forward validation for time series\n",
    "- Train with appropriate callbacks and monitoring\n",
    "- Avoid data leakage in validation\n",
    "- Optimize hyperparameters\n",
    "\n",
    "---\n",
    "\n",
    "## Time Series Validation Strategy\n",
    "\n",
    "Standard cross-validation doesn't work for time series - we must respect temporal order to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2a31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data/processed/mmm_data_with_features.csv')\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "print(f\"Data shape: {data.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "exclude_cols = ['Date', 'GMV', 'product_category', 'product_subcategory']\n",
    "feature_cols = [col for col in data.columns if col not in exclude_cols]\n",
    "X = data[feature_cols].values\n",
    "y = data['GMV'].values\n",
    "\n",
    "print(f\"Features: {X.shape}\")\n",
    "print(f\"Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1bad8c",
   "metadata": {},
   "source": [
    "## Walk-Forward Validation\n",
    "\n",
    "This technique uses an expanding window approach:\n",
    "- Train on past data, validate on future data\n",
    "- Gradually expand training set\n",
    "- Never use future information for past predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658380b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_walk_forward_splits(X, y, n_splits=5, test_size=0.2):\n",
    "    '''\n",
    "    Create walk-forward validation splits for time series.\n",
    "    '''\n",
    "    n_samples = len(X)\n",
    "    test_samples = int(n_samples * test_size)\n",
    "\n",
    "    splits = []\n",
    "    min_train_size = n_samples // (n_splits + 2)\n",
    "\n",
    "    for i in range(n_splits):\n",
    "        train_end = min_train_size * (i + 2)\n",
    "        val_start = train_end\n",
    "        val_end = min(val_start + test_samples, n_samples)\n",
    "\n",
    "        if val_end > n_samples:\n",
    "            break\n",
    "\n",
    "        train_idx = np.arange(0, train_end)\n",
    "        val_idx = np.arange(val_start, val_end)\n",
    "\n",
    "        splits.append((train_idx, val_idx))\n",
    "\n",
    "        print(f\"Split {i+1}: Train [0:{train_end}], Val [{val_start}:{val_end}]\")\n",
    "\n",
    "    return splits\n",
    "\n",
    "# Create validation splits\n",
    "splits = create_walk_forward_splits(X, y, n_splits=3)\n",
    "print(f\"\\nCreated {len(splits)} walk-forward splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc9ac0",
   "metadata": {},
   "source": [
    "## Training with Callbacks\n",
    "\n",
    "We'll use callbacks to:\n",
    "- Stop early if no improvement (prevent overfitting)\n",
    "- Reduce learning rate when stuck (escape plateaus)\n",
    "- Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7042618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nam_model(model, X_train, y_train, X_val, y_val, epochs=100):\n",
    "    '''\n",
    "    Train NAM model with proper callbacks and monitoring.\n",
    "    '''\n",
    "\n",
    "    # Scale features\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "\n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_val_scaled = scaler_X.transform(X_val)\n",
    "\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    y_val_scaled = scaler_y.transform(y_val.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'models/best_nam.keras',\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=0\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        [X_train_scaled[:, i:i+1] for i in range(X_train_scaled.shape[1])],\n",
    "        y_train_scaled,\n",
    "        validation_data=(\n",
    "            [X_val_scaled[:, i:i+1] for i in range(X_val_scaled.shape[1])],\n",
    "            y_val_scaled\n",
    "        ),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    return history, scaler_X, scaler_y\n",
    "\n",
    "# Example training (simplified)\n",
    "print(\"Training would proceed with walk-forward validation...\")\n",
    "print(\"Each split would be trained and evaluated separately\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e50ce",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "For business decisions, we need interpretable metrics:\n",
    "- **R^2**: Variance explained\n",
    "- **MAPE**: Average percentage error\n",
    "- **MAE**: Average absolute error in dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f875233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    '''Calculate comprehensive performance metrics.'''\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    # MAPE\n",
    "    mask = y_true != 0\n",
    "    mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "    # SMAPE\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "    mask = denominator != 0\n",
    "    smape = np.mean(np.abs(y_true[mask] - y_pred[mask]) / denominator[mask]) * 100\n",
    "\n",
    "    return {\n",
    "        'R^2': r2,\n",
    "        'MAE': mae,\n",
    "        'MAPE': mape,\n",
    "        'SMAPE': smape\n",
    "    }\n",
    "\n",
    "# Example metrics\n",
    "y_true_example = np.array([100, 200, 300, 400, 500])\n",
    "y_pred_example = np.array([110, 190, 310, 380, 520])\n",
    "\n",
    "metrics = calculate_metrics(y_true_example, y_pred_example)\n",
    "print(\"Example Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8366d9",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Training Best Practices:\n",
    "1. **Walk-forward validation** prevents data leakage\n",
    "2. **Early stopping** prevents overfitting\n",
    "3. **Learning rate reduction** helps convergence\n",
    "4. **Feature scaling** is essential for neural networks\n",
    "\n",
    "### Validation Strategy:\n",
    "- Never use future data to predict past\n",
    "- Expand training set progressively\n",
    "- Evaluate on truly unseen data\n",
    "\n",
    "### Next Steps:\n",
    "In Notebook 5, we'll generate comprehensive diagnostic visualizations."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}